   70  cd Assignment1
   71  ls
   72  history > cmds.log
   73  ls
   74  cd ..
   75  git add Assignment1
   76  git status
   77  cd Assignment1
   78  git commit -m"add Assignment1"
   79  git push origin master
   80  cd myDir2
   81  ls
   82  cd ..
   83  myDir2
   84  cd myDir2
   85  git push origin master
   86  cd ..
   87  cd ..script capture.log
   88  script capture.log
   89  u
   90  cd ..
   91  cd
   92  stop
   93  cat capture.log
   94  vi ws4.txt
   95  l
   96  w
   97  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f3 >  Subscribers/United_States.txt
   98  grep "India" 'Global YouTube Statistics.csv' | cut -d ',' -f3 >  Subscribers/India.txt
   99  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4_means.txt
  100  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt > ws4_means.txt
  101  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt >> ws4_means.txt
  102  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4_means.txt
  103  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4_means.txt
  104  vi ws4.txt
  105  vi ws4_means.txt
  106  vi Subscribers/India.txt
  107  l
  108  w
  109  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/Global%20YouTube%20Statistics.csv
  110  mkdir Subscribers
  111  head - 1 'Global YouTube Statistics.csv'
  112  head -n 1 Global YouTube Statistics.csv' | grep -i "Subscribers"
  113  h
  114  done
  115  sto
  116  stop
  117  grep "United States" 'Global YouTube Statistics.csv' | -f3 >  Subscribers/United_States.txt
  118  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f3 >  Subscribers/United_States.txt
  119  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f3 >  Subscribers/India.txt
  120  grep "India" 'Global YouTube Statistics.csv' | cut -d ',' -f3 >  Subscribers/India.txt
  121  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4.txt
  122  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4.txt
  123  vi ~/.bashrc
  124  cat Subscribers/United_States.txt | paste -sd+ - | bc -l
  125  vi ws4.txt
  126  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4_means.txt
  127  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4_means.txt
  128  vi ws4_means.txt
  129  cat ~/cs131/Worksheet4/Subscribers/United_States.txt | paste -sd+ - | bc -l > ~/cs131/Worksheet4/ws4_means.txt
  130  vi United_States.txt
  131  vi Subscribers/United_States.txt
  132  cat Subscribers/United_States.txt | paste -sd+ - | bc -l > ws4_means.txt
  133  vi ws4_means.txt
  134  echo Subscribers/United_States.txt | bc
  135  bc
  136  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4_means.txt
  137  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4.txt
  138  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4_means.txt
  139  vi ws4_means.txt
  140  awk '{ total += $1 } END { print total / NR }' Subscribers/United_States.txt > ws4_means.txt
  141  awk '{ total += $1 } END { print total / NR }' Subscribers/India.txt >> ws4_means.txt
  142  vi ws4.txt
  143  script ws4.txt
  144  :w
  145  exut
  146  exit
  147  cd cs131
  148  ls
  149  rmkdir ws4.txt
  150  rm ws4.txt
  151  ls
  152  cd Worksheet4
  153  ls
  154  nano ~/.bashrc
  155  l
  156  nano ~/.bashrc
  157  script ws4.txt
  158  cd cs131
  159  ls
  160  git add Worksheet4
  161  cd Worksheet4
  162  ls
  163  cd Subscribers
  164  ls
  165  cd ..
  166  cat ws4_means.txt
  167  cat ws4.txt
  168  cd ..
  169  cd cs131
  170  ls
  171  mkdir Worksheet4
  172  script ws4.txt
  173  nano ~/.bashrc
  174  l
  175  w
  176  l
  177  nano ~/.bashrc
  178  source ~/.bashrc
  179  l
  180  w
  181  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/Global%20YouTube%20Statistics.csv
  182  cd ..
  183  cd cs131
  184  cd cs131
  185  cd Worksheet4
  186  git commit -m"Add Worksheet4"
  187  git push origin master
  188  cd cs131
  189  cd Worksheet4
  190  history > cmds.log
  191  cd cmds.log
  192  ls
  193  cat cmds.log
  194  cd ..
  195  git add Worksheet4
  196  cd Worksheet4
  197  git commit - m
  198  git commit -m "add worksheet4"
  199  git push origin master
  200  cd ..
  201  tar
  202  man
  203  tar
  204  man
  205  tar --help
  206  cd cs131
  207  mkdir Assignment2
  208  cd Assignment2
  209  vi Assignment2.txt
  210  find /etc -type f > one.txt 2> two.txt
  211  cat one.txt
  212  cat two.txt
  213      PID TTY          TIME CMD
  214  2358192 ?        00:00:04 systemd
  215  2358194 ?        00:00:00 (sd-pam)
  216  2509382 ?        00:00:00 sshd
  217  2509385 pts/94   00:00:00 bash
  218  2525798 ?        00:00:00 sshd
  219  2525804 pts/60   00:00:00 bash
  220  2532533 pts/94   00:00:00 ps
  221  ps -u hamzaf23
  222  cd cs131
  223  cd Assignment2
  224  pgrep init
  225  ps -u hamzaf23
  226  cd ..
  227  cd cs131
  228  cd Assignment2
  229  ps -u hamzaf23
  230  ps aux
  231  cd cs131
  232  cd Assignment2
  233  vi Assigment2.txt
  234  vi Assignment2.txt
  235  cut -d, -f1,2 dataset.csv | sort | uniq -c | sort -nr | head -3
  236  find /etc -type f > one.txt 2> two.txt
  237  vi file.txt
  238  ps -u your_username
  239  ps -u hamzaf23@sjsu
  240  whoami
  241  ps -u hamzaf23
  242  vi file.txt
  243  ps -u hamzaf23
  244  vi file.txt
  245  ps aux
  246  cd cs131
  247  cd Assignment2
  248  cat one.txt
  249  cat two.txt
  250  When I do cat one.txt, I see a list of all the regular files found in the /etc directory and its subdirectory. When I do two.txt I see error messeges
  251  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/Global%20YouTube%20Statistics.csv
  252  cut -d, -f3,4 Global\ YouTube\ Statistics.csv | sort | uniq -c | sort -nr | head -3
  253  cut -d, -f8,9 "Global YouTube Statistics.csv" | sort | uniq -c | sort -nr | head -3
  254  cut -d, -f2,3 YouTubeData.csv | sort | uniq -c | sort -nr
  255  cut -d, -f2,3 "Global YouTube Statistics" | sort | uniq -c | sort -nr
  256  cut -d, -f2,3 "Global YouTube Statistics.cvs" | sort | uniq -c | sort -nr
  257  cut -d, -f2,3 "Global YouTube Statistics.csv" | sort | uniq -c | sort -nr
  258  cut -d ',' -f 2,3 "Global YouTube Statistics.csv" | sort | uniq -c | sort -nr
  259  cut -d ',' -f 7 "Global Youtube Statistics.csv" | cut -d '/' -f 3 | sort | uniq -c | sort -nr
  260  2. Which [Month, Year] had the most YouTube channels created   [ Use the created year and created month columns ] 
  261  Your answer should contain what commands you used along with the output. 
  262  Requirement: You should apply cut sort and uniq commands to accomplish this task. You can use commands in addition to these as well but solve the actual problem using cut sort and uniq.
  263  Example :
  264  As per the Dataset, Top 3 [Month, Year] with the most number of YouTube channels created were :
  265  1. December,2025 with 35 channels  
  266  2. December,2060 with 20 channels 
  267  3. January,1998 with 16 channels
  268  [ Replace months and years above with your answer ]
  269  The command(s) used to find it was this: _______________
  270  Explain the command along with the parameters used and the reason for using them.
  271  head Global Youtube Statistics.csv
  272  head "Global Youtube Statistics.csv"
  273  "Global YouTube Statistics.csv"
  274  head "Global YouTube Statistics.csv"
  275  head -n 1 'Global YouTube Statistics.csv' | tr ',' '\n' | grep -n 'created_year'
  276  head -n 1 'Global YouTube Statistics.csv' | tr ',' '\n' | grep -n 'created_month'
  277  cut -d ',' -f 20,21 'Global YouTube Statistics.csv' | sort | uniq -c | sort -nr | head -3
  278  pgrep systemd
  279  pgrep init
  280  cd cs131
  281  cd Assignment2
  282  vi Assignment2.txt
  283  history > cmds.log
  284  cd ..
  285  git add 
  286  git add .
  287  cd cs131
  288  git add Assignment2
  289  cd Assignment2
  290  git commit -m"add"
  291  git origin push master
  292  git origin master
  293  git push origin master
  294  cd awk
  295  mkdir Worksheet5
  296  cd Worksheet5
  297  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/Global%20YouTube%20Statistics.csv
  298  ls
  299  music_count=0
  300  entertainment_count=0
  301  gaming_count=0
  302  comedy_count=0
  303  music_count=0
  304  entertainment_count=0
  305  gaming_count=0
  306  comedy_count=0
  307  while IFS=, read -r category country; do   if [ "$country" == "United States" ]; then     case "$category" in       "Music")         echo "$category" >> "Workhsheet 5/United States/Music.txt";         ((music_count++));         ;;       "Entertainment")         echo "$category" >> "Workhsheet 5/United States/Entertainment.txt";         ((entertainment_count++));         ;;       "Gaming")         echo "$category" >> "Workhsheet 5/United States/Gaming.txt";         ((gaming_count++));         ;;       "Comedy")         echo "$category" >> "Workhsheet 5/United States/Comedy.txt";         ((comedy_count++));         ;;     esac;   fi; done < "Global YouTube Statistics.csv"
  308  echo "Music: $music_count" >> "ws5.txt"
  309  echo "Entertainment: $entertainment_count" >> "ws5.txt"
  310  echo "Gaming: $gaming_count" >> "ws5.txt"
  311  echo "Comedy: $comedy_count" >> "ws5.txt"
  312  # Initialize a counter for each category
  313  music_count=0
  314  entertainment_count=0
  315  gaming_count=0
  316  comedy_count=0
  317  # Loop through the CSV file and categorize entries
  318  while IFS=, read -r category country; do   if [ "$country" == "United States" ]; then     case "$category" in       "Music")         echo "$category" >> "Workhsheet 5/United States/Music.txt";         ((music_count++));         ;;       "Entertainment")         echo "$category" >> "Workhsheet 5/United States/Entertainment.txt";         ((entertainment_count++));         ;;       "Gaming")         echo "$category" >> "Workhsheet 5/United States/Gaming.txt";         ((gaming_count++));         ;;       "Comedy")         echo "$category" >> "Workhsheet 5/United States/Comedy.txt";         ((comedy_count++));         ;;     esac;   fi; done < "Global YouTube Statistics.csv"
  319  # Output the counts to a ws5.txt file
  320  echo "Music: $music_count" >> "ws5.txt"
  321  echo "Entertainment: $entertainment_count" >> "ws5.txt"
  322  echo "Gaming: $gaming_count" >> "ws5.txt"
  323  echo "Comedy: $comedy_count" >> "ws5.txt"
  324  music_count=0
  325  entertainment_count=0
  326  gaming_count=0
  327  comedy_count=0
  328  while IFS=, read -r category country; do   if [ "$country" == "United States" ]; then     case "$category" in       "Music")         echo "$category" >> "Workhsheet 5/United States/Music.txt";         ((music_count++));         ;;       "Entertainment")         echo "$category" >> "Workhsheet 5/United States/Entertainment.txt";         ((entertainment_count++));         ;;       "Gaming")         echo "$category" >> "Workhsheet 5/United States/Gaming.txt";         ((gaming_count++));         ;;       "Comedy")         echo "$category" >> "Workhsheet 5/United States/Comedy.txt";         ((comedy_count++));         ;;     esac;   fi; done < "Global YouTube Statistics.csv"
  329  echo "Music: $music_count" >> "ws5.txt"
  330  echo "Entertainment: $entertainment_count" >> "ws5.txt"
  331  echo "Gaming: $gaming_count" >> "ws5.txt"
  332  echo "Comedy: $comedy_count" >> "ws5.txt"
  333  vi ws5.txt
  334  cat ws5.txt
  335  echo "Entertainment: $entertainment_count" >> "ws5.txt"
  336  echo "Gaming: $gaming_count" >> "ws5.txt"
  337  echo "Comedy: $comedy_count" >> "ws5.txt"
  338  cat ws5.txt
  339  while IFS=, read -r category country; do   if [ "$country" == "United States" ]; then     case "$category" in       "Music")         echo "$category" >> "Workhsheet 5/United States/Music.txt";         ((music_count++));         ;;       "Entertainment")         echo "$category" >> "Workhsheet 5/United States/Entertainment.txt";         ((entertainment_count++));         ;;       "Gaming")         echo "$category" >> "Workhsheet 5/United States/Gaming.txt";         ((gaming_count++));         ;;       "Comedy")         echo "$category" >> "Workhsheet 5/United States/Comedy.txt";         ((comedy_count++));         ;;     esac;   fi; done < "Global YouTube Statistics.csv"
  340  echo "Music: $music_count" >> "ws5.txt"
  341  echo "Entertainment: $entertainment_count" >> "ws5.txt"
  342  echo "Gaming: $gaming_count" >> "ws5.txt"
  343  echo "Comedy: $comedy_count" >> "ws5.txt"
  344  cat ws5.txt
  345  #ji
  346  # Loop through each category and extract entries to respective files
  347  categories=("Music" "Entertainment" "Gaming" "Comedy")
  348  for category in "${categories[@]}"; do   grep "United States" "Global YouTube Statistics.csv" | grep "$category" > "Workhsheet 5/United States/$category.txt"; done
  349  # Count the number of entries in each category file and save to ws5.txt
  350  echo "Number of entries in 'Music.txt':" $(wc -l "Workhsheet 5/United States/Music.txt" | awk '{print $1}') > ws5.txt
  351  echo "Number of entries in 'Entertainment.txt':" $(wc -l "Workhsheet 5/United States/Entertainment.txt" | awk '{print $1}') >> ws5.txt
  352  echo "Number of entries in 'Gaming.txt':" $(wc -l "Workhsheet 5/United States/Gaming.txt" | awk '{print $1}') >> ws5.txt
  353  echo "Number of entries in 'Comedy.txt':" $(wc -l "Workhsheet 5/United States/Comedy.txt" | awk '{print $1}') >> ws5.txt
  354  ls
  355  for category in "${categories[@]}"; do   grep "United States" "Global YouTube Statistics.csv" | grep "$category" > "Worksheet5/United States/$category.txt"; done
  356  # Count the number of entries in each category file and save to ws5.txt
  357  echo "Number of entries in 'Music.txt':" $(wc -l "Worksheet5/United States/Music.txt" | awk '{print $1}') > ws5.txt
  358  echo "Number of entries in 'Entertainment.txt':" $(wc -l "Worksheet5/United States/Entertainment.txt" | awk '{print $1}') >> ws5.txt
  359  echo "Number of entries in 'Gaming.txt':" $(wc -l "Worksheet5/United States/Gaming.txt" | awk '{print $1}') >> ws5.txt
  360  echo "Number of entries in 'Comedy.txt':" $(wc -l "Worksheet5/United States/Comedy.txt" | awk '{print $1}') >> ws5.txt
  361  for category in "${categories[@]}"; do   grep "United States" "Global YouTube Statistics.csv" | grep "$category" > "Worksheet5/United States/$category.txt"; done
  362  # Count the number of entries in each category file and save to ws5.txt
  363  echo "Number of entries in 'Music.txt':" $(wc -l "United States/Music.txt" | awk '{print $1}') > ws5.txt
  364  echo "Number of entries in 'Entertainment.txt':" $(wc -l "United States/Entertainment.txt" | awk '{print $1}') >> ws5.txt
  365  echo "Number of entries in 'Gaming.txt':" $(wc -l "United States/Gaming.txt" | awk '{print $1}') >> ws5.txt
  366  echo "Number of entries in 'Comedy.txt':" $(wc -l "United States/Comedy.txt" | awk '{print $1}') >> ws5.txt
  367  cat ws5.txt
  368  while IFS=, read -r _ country category _; do     if [ "$country" == "United States" ]; then         case "$category" in             "Music")                 echo "$category" >> "Worksheet5/United States/Music.txt";                 ;;             "Entertainment")                 echo "$category" >> "Worksheet5/United States/Entertainment.txt";                 ;;             "Gaming")                 echo "$category" >> "Worksheet5/United States/Gaming.txt";                 ;;             "Comedy")                 echo "$category" >> "Worksheet5/United States/Comedy.txt";                 ;;         esac;     fi; done < "Global YouTube Statistics.csv"
  369  cat United States/Comedy.txt
  370  while IFS=, read -r _ country category _; do     if [ "$country" == "United_States" ]; then         case "$category" in             "Music")                 echo "$category" >> "Worksheet5/United_States/Music.txt";                 ;;             "Entertainment")                 echo "$category" >> "Worksheet5/United_States/Entertainment.txt";                 ;;             "Gaming")                 echo "$category" >> "Worksheet5/United_States/Gaming.txt";                 ;;             "Comedy")                 echo "$category" >> "Worksheet5/United_States/Comedy.txt";                 ;;         esac;     fi; done < "Global YouTube Statistics.csv"
  371  cat United_States/Comedy.txt
  372  cat Worksheet5/United_States/Comedy.txt
  373  ls
  374  while IFS=, read -r _ country category _; do     if [ "$country" == "United_States" ]; then         case "$category" in             "Music")                 echo "$category" >> "United_States/Music.txt";                 ;;             "Entertainment")                 echo "$category" >> "United_States/Entertainment.txt";                 ;;             "Gaming")                 echo "$category" >> "United_States/Gaming.txt";                 ;;             "Comedy")                 echo "$category" >> "United_States/Comedy.txt";                 ;;         esac;     fi; done < "Global YouTube Statistics.csv"
  375  ls
  376  wc -l "United_States/Music.txt" "United_States/Entertainment.txt" "United_States/Gaming.txt" "United_States/Comedy.txt" > ws5.txt
  377  while IFS=, read -r _ country category _; do     if [ "$country" == "United_States" ]; then         case "$category" in             "Music")                 mkdir "United_States";                 echo "$category" >> "United_States/Music.txt";                 ;;             "Entertainment")                 mkdir "United_States";                 echo "$category" >> "United_States/Entertainment.txt";                 ;;             "Gaming")                 mkdir "United_States";                 echo "$category" >> "United_States/Gaming.txt";                 ;;             "Comedy")                 mkdir "United_States";                 echo "$category" >> "United_States/Comedy.txt";                 ;;         esac;     fi; done < "Global YouTube Statistics.csv"
  378  wc -l "United_States/Music.txt" "United_States/Entertainment.txt" "United_States/Gaming.txt" "United_States/Comedy.txt" > ws5.txt
  379  while IFS=, read -r _ country category _; do     if [ "$country" == "United_States" ]; then         case "$category" in             "Music")                 mkdir "United_States";                 echo "$category" >> "United_States/Music.txt";                 ;;             "Entertainment")                 mkdir "United_States";                 echo "$category" >> "United_States/Entertainment.txt";                 ;;             "Gaming")                 mkdir "United_States";                 echo "$category" >> "United_States/Gaming.txt";                 ;;             "Comedy")                 mkdir "United_States";                 echo "$category" >> "United_States/Comedy.txt";                 ;;         esac;     fi; done < "Global YouTube Statistics.csv"
  380  nano ~/.bashrc
  381  cat ~/.bashrc
  382  alias c
  383  c
  384  nano ~/.bashrc
  385  alias c
  386  c
  387  awk -F, '$2 == "United_States" { 
  388      category = $3; 
  389      gsub(/ /, "_", category); 
  390      filename = "United_States/" category ".txt"; 
  391      print $3 >> filename; 
  392  }' "Global YouTube Statistics.csv"
  393  wc -l "United_States/Music.txt" "United_States/Entertainment.txt" "United_States/Gaming.txt" "United_States/Comedy.txt" > ws5.txt
  394  awk -F, '$2 == "United_States" { 
  395      category = $3; 
  396      gsub(/ /, "_", category); 
  397      filename = "United_States/" category ".txt"; 
  398      system("mkdir -p United_States");
  399      print $3 >> filename; 
  400  }' "Global YouTube Statistics.csv"
  401  awk -F, '$2 == "United_States" { 
  402      category = $3; 
  403      gsub(/ /, "_", category); 
  404      filename = "United_States/" category ".txt"; 
  405      system("mkdir -p United_States");
  406      print $3 >> filename; 
  407  }' "Global YouTube Statistics.csv"
  408  wc -l "United_States/Music.txt" "United_States/Entertainment.txt" "United_States/Gaming.txt" "United_States/Comedy.txt" > ws5.txt
  409  awk -F, '$2 == "United_States" {
  410      category = $3;
  411      gsub(/ /, "_", category);
  412      filename = "United_States/" category ".txt";
  413      print $3 >> filename;
  414  }' "Global YouTube Statistics.csv"
  415  wc -l United_States/Music.txt United_States/Entertainment.txt United_States/Gaming.txt United_States/Comedy.txt > ws5.txt
  416  categories=("Music" "Entertainment" "Gaming" "Comedy")
  417  # Initialize counts for each category
  418  for category in "${categories[@]}"; do     count=0;     grep "United States,.*$category" "Global YouTube Statistics.csv" |         awk -F',' '{print $0 > "Workhsheet 5/United States/"$3".txt"; count++}';     echo "Count for $category: $count"; done
  419  # Count the entries in each category file
  420  for category in "${categories[@]}"; do     wc -l "Workhsheet 5/United States/$category.txt"; done > ws5.txt
  421  ls
  422  mkdir "Worksheet 5/United States"
  423  mkdir -p "Workhsheet 5/United States"
  424  categories=("Music" "Entertainment" "Gaming" "Comedy")
  425  # Initialize counts for each category
  426  for category in "${categories[@]}"; do     count=0;     grep "United States,.*$category" "Global YouTube Statistics.csv" |         awk -F',' '{print $0 > "Workhsheet 5/United States/"$3".txt"; count++}';     echo "Count for $category: $count"; done
  427  # Count the entries in each category file
  428  for category in "${categories[@]}"; do     wc -l "Workhsheet 5/United States/$category.txt"; done > ws5.txt
  429  mkdir -p "Workhsheet 5/United States"
  430  categories=("Music" "Entertainment" "Gaming" "Comedy")
  431  for category in "${categories[@]}"; do     grep -E "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  432  mkdir -p "Workhsheet 5/United States"
  433  categories=("Music" "Entertainment" "Gaming" "Comedy")
  434  for category in "${categories[@]}"; do     grep -E "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  435  mkdir -p "Workhsheet 5/United States"
  436  categories=("Music" "Entertainment" "Gaming" "Comedy")
  437  for category in "${categories[@]}"; do     grep -E "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  438  mkdir -p "Workhsheet 5/United States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep -E "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  439  ls
  440  wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  441  cat ws5.txt
  442  mkdir -p "Workhsheet 5/United States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep -E "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  443  mkdir -p "Workhsheet 5/United States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  444  wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  445  cat ws5.txt
  446  mkdir -p "Workhsheet 5/United States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global YouTube Statistics.csv" >> "Workhsheet 5/United States/${category}.txt"; done
  447  wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  448  vi ws5.txt
  449  cat ws5.txt
  450  wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  451  cat ws5.txt
  452  history > cmds.log
  453  cd cs131
  454  cd Worksheet5
  455  ls
  456  cd ..
  457  ls
  458  mv Worksheet5 cs131
  459  ls
  460  cd cs131
  461  ls
  462  cd Worksheet5
  463  vi script.sh
  464  nano script.sh
  465  cat script.sh
  466  chmod +x script.sh
  467  ./script.sh
  468  cat ws5.txt
  469  vi script.sh
  470  touch "Workhsheet 5/United States/Gaming.txt"
  471  cat "Workhsheet 5/United States/Gaming.txt"
  472  cat ws5.txt
  473  ./script.sh
  474  cat ws5.txt
  475  vi script.sh
  476  ./script.sh
  477  cat ws5.txt
  478  vi script.sh
  479  ./script.sh
  480  cat ws5.txt
  481  vi script.sh
  482  cat script.sh
  483  ./script.sh
  484  chmod +x script.sh
  485  ./script.sh
  486  cat ws5.txt
  487  vi script.sh
  488  mkdir -p "Workhsheet 5/United States" && music_count=0 && entertainment_count=0 && gaming_count=0 && comedy_count=0 && while IFS=, read -r channel category country; do [ "$country" = "United States" ] && case "$category" in "Music") ((music_count++)) ;; "Entertainment") ((entertainment_count++)) ;; "Gaming") ((gaming_count++)) ;; "Comedy") ((comedy_count++)) ;; esac; done < "Global YouTube Statistics.csv" && echo "Music: $music_count" > ws5.txt && echo "Entertainment: $entertainment_count" >> ws5.txt && echo "Gaming: $gaming_count" >> ws5.txt && echo "Comedy: $comedy_count" >> ws5.txt
  489  cat ws5.txt
  490  mkdir -p "Workhsheet 5/United States" && music_count=0 && entertainment_count=0 && gaming_count=0 && comedy_count=0 && while IFS=, read -r channel category country; do [ "$country" = "United States" ] && case "$category" in "Music") ((music_count++)) ;; "Entertainment") ((entertainment_count++)) ;; "Gaming") ((gaming_count++)) ;; "Comedy") ((comedy_count++)) ;; esac; done < "Global YouTube Statistics.csv" && echo "Music: $music_count" > ws5.txt && echo "Entertainment: $entertainment_count" >> ws5.txt && echo "Gaming: $gaming_count" >> ws5.txt && echo "Comedy: $comedy_count" >> ws5.txt
  491  mkdir -p "Workhsheet 5/United States" && music_count=0 && entertainment_count=0 && gaming_count=0 && comedy_count=0 && while IFS=, read -r channel category country; do [ "$country" = "United States" ] && case "$category" in "Music") ((music_count++)) ;; "Entertainment") ((entertainment_count++)) ;; "Gaming") ((gaming_count++)) ;; "Comedy") ((comedy_count++)) ;; esac; done < "Global YouTube Statistics.csv" && echo "Music: $music_count" > ws55.txt && echo "Entertainment: $entertainment_count" >> ws55.txt && echo "Gaming: $gaming_count" >> ws55.txt && echo "Comedy: $comedy_count" >> ws55.txt
  492  cat ws55.txt
  493  ls
  494  categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do awk -F, -v category="$category" '$3 == "United States" && $4 == category {print $0}' "Global YouTube Statistics.csv" > "Workhsheet 5/United States/$category.txt"; done; wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  495  cat ws5.txt
  496  categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do awk -F, -v category="$category" '$3 == "United States" && $4 == category {print $0}' 'Global YouTube Statistics.csv' > "Workhsheet 5/United States/$category.txt"; done; wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  497  cat ws5.txt
  498  ls
  499  categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do awk -F, -v category="$category" '$3 == "United States" && $4 == category {print $0}' 'Global YouTube Statistics.csv' > "Worksheet 5/United States/$category.txt"; done; wc -l "Worksheet 5/United States/Music.txt" "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" > ws5.txt
  500  categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do awk -F, -v category="$category" '$3 == "United States" && $4 == category {print $0}' 'Global YouTube Statistics.csv' > "Workhsheet 5/United States/$category.txt"; done; wc -l "Workhsheet 5/United States/Music.txt" "Workhsheet 5/United States/Entertainment.txt" "Workhsheet 5/United States/Gaming.txt" "Workhsheet 5/United States/Comedy.txt" > ws5.txt
  501  cat ws5.txt
  502  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/
  503  United States/${category}.txt"; done
  504  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/; United States/${category}.txt"; done
  505  exit
  506  exit
  507  quit
  508  exit
  509  exit
  510  eixt
  511  eixt
  512  exit
  513  "wowo"
  514  'exit'
  515  exit
  516  exit
  517  exit
  518  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/
  519  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/United States/${category}.txt"; done
  520  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/United States/${category}.txt"; done
  521  cd cs131
  522  cd Worksheet5
  523  vi ws5.txt
  524  input_file="Global YouTube Statistics.csv"
  525  output_directory="Workhsheet 5/United States"
  526  mkdir -p "$output_directory"
  527  categories=("Music" "Entertainment" "Gaming" "Comedy")
  528  for category in "${categories[@]}"; do     touch "$output_directory/$category.txt"; done
  529  count_and_write_to_ws5() {     category_name="$1";     category_file="$output_directory/$category_name.txt";     entry_count=$(wc -l < "$category_file");     echo "$category_name: $entry_count" >> "ws5.txt"; }
  530  IFS=$'\n'
  531  while read -r line; do
  532      IFS=',' read -r -a fields <<< "$line";      if [[ "${fields[3]}" == "United States" ]]; then         for category in "${categories[@]}"; do             if [[ "${fields[4]}" == "$category" ]]; then                 echo "$line" >> "$output_directory/$category.txt";             fi;         done;     fi; done < "$input_file"
  533  for category in "${categories[@]}"; do     count_and_write_to_ws5 "$category"; done
  534  vi script.sh
  535  input_file="Global YouTube Statistics.csv"; output_directory="Workhsheet 5/United States"; mkdir -p "$output_directory"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do touch "$output_directory/$category.txt"; done; count_and_write_to_ws5() { category_name="$1"; category_file="$output_directory/$category_name.txt"; entry_count=$(wc -l < "$category_file"); echo "$category_name: $entry_count" >> "ws5.txt"; }; IFS=$'\n'; while read -r line; do IFS=',' read -r -a fields <<< "$line"; if [[ "${fields[3]}" == "United States" ]]; then for category in "${categories[@]}"; do if [[ "${fields[4]}" == "$category" ]]; then echo "$line" >> "$output_directory/$category.txt"; fi; done; fi; done < "$input_file"; for category in "${categories[@]}"; do count_and_write_to_ws5 "$category"; done
  536  cat ws5.txt
  537  ls
  538  cat 'Global YouTube Statistics.csv'
  539  grep Music
  540  touch ws5.txt
  541  input_file="Global YouTube Statistics.csv"; output_directory="Workhsheet 5/United States"; mkdir -p "$output_directory"; touch "ws5.txt"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do touch "$output_directory/$category.txt"; done; count_and_write_to_ws5() { category_name="$1"; category_file="$output_directory/$category_name.txt"; entry_count=$(wc -l < "$category_file"); echo "$category_name: $entry_count" >> "ws5.txt"; }; IFS=$'\n'; while read -r line; do IFS=',' read -r -a fields <<< "$line"; if [[ "${fields[3]}" == "United States" ]]; then for category in "${categories[@]}"; do if [[ "${fields[4]}" == "$category" ]]; then echo "$line" >> "$output_directory/$category.txt"; fi; done; fi; done < "$input_file"; for category in "${categories[@]}"; do count_and_write_to_ws5 "$category"; done
  542  cat ws5.txt
  543  vi ws5.txt
  544  cat ws5.txt
  545  input_file="Global YouTube Statistics.csv"; output_directory="Workhsheet 5/United States"; mkdir -p "$output_directory"; touch "ws5.txt"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do touch "$output_directory/$category.txt"; done; count_and_write_to_ws5() { category_name="$1"; category_file="$output_directory/$category_name.txt"; entry_count=$(wc -l < "$category_file"); echo "$category_name: $entry_count" >> "ws5.txt"; }; IFS=$'\n'; while read -r line; do IFS=',' read -r -a fields <<< "$line"; if [[ "${fields[3]}" == "United States" ]]; then for category in "${categories[@]}"; do if [[ "${fields[4]}" == "$category" ]]; then echo "$line" >> "$output_directory/$category.txt"; fi; done; fi; done < "$input_file"; for category in "${categories[@]}"; do count_and_write_to_ws5 "$category"; done
  546  cat ws5.txt
  547  input_file="Global YouTube Statistics.csv"; output_directory="Workhsheet 5/United States"; mkdir -p "$output_directory"; touch "ws5.txt"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do touch "$output_directory/$category.txt"; done; IFS=$'\n'; cat "$input_file" | while read -r line; do IFS=',' read -r -a fields <<< "$line"; if [ "${fields[3]}" = "United States" ]; then for category in "${categories[@]}"; do if [ "${fields[4]}" = "$category" ]; then echo "$line" >> "$output_directory/$category.txt"; fi; done; fi; done; for category in "${categories[@]}"; do echo "$category: $(cat "$output_directory/$category.txt" | wc -l)" >> "ws5.txt"; done
  548  cat ws5.txt
  549  input_file="Global YouTube Statistics.csv"; output_directory="Workhsheet 5/United States"; mkdir -p "$output_directory"; touch "results.txt"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do touch "$output_directory/$category.txt"; done; IFS=$'\n'; cat "$input_file" | while read -r line; do IFS=',' read -r -a fields <<< "$line"; if [ "${fields[3]}" = "United States" ]; then for category in "${categories[@]}"; do if [ "${fields[4]}" = "$category" ]; then echo "$line" >> "$output_directory/$category.txt"; fi; done; fi; done; for category in "${categories[@]}"; do echo "$category: $(cat "$output_directory/$category.txt" | wc -l)" >> "results.txt"; done
  550  cat results.txt
  551  mkdir -p "Worksheet 5/United Stat es' && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@1}"; do grep "United States, .*category" "Global YouTube Statistics.cv' >> "Workhsheet 5/ United States/${category}.txt"; done
  552  mkdir -p "Worksheet 5/Untied States' 
  553  mkdir -p "Worksheet 5/Untied States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global Youtube Statistics.csv" >> Worksheet 5/United States/${category}.txt"; done
  554  ls
  555  mkdir -p "Worksheet 5/Untied States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global Youtube Statistics.csv" >> Worksheet 5/United States/${category}.txt"; done
  556  mkdir -p "Worksheet 5/Untied States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global Youtube Statistics.csv" >> Worksheet 5/United States/${category}.txt"; done 
  557  vi script.sh
  558  ./script.sh
  559  vi script.sh
  560  mkdir -p "Worksheet 5/Untied States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global Youtube Statistics.csv" >> "Worksheet 5/United States/${category}.txt"; done
  561  mkdir -p "Worksheet 5/United States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global Youtube Statistics.csv" >> "Worksheet 5/United States/${category}.txt"; done
  562  ls
  563  mkdir -p "Worksheet 5/Untied States" && categories=("Music" "Entertainment" "Gaming" "Comedy") && for category in "${categories[@]}"; do grep "United States,.*$category" "Global YouTube Statistics.csv" >> "Worksheet 5/United States/${category}.txt"; done
  564  cat ws5.txt
  565  wc -l "Worksheet5/United_States/Music.txt" "Worksheet5/United_States/Entertainment.txt" "Worksheet5/United_States/Gaming.txt" "Worksheet5/United_States/Comedy.txt" > ws5.txt
  566  wc -w "Worksheet 5/United States/Music.txt" "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" > ws5.txt
  567  cat ws5.txt
  568  vi script.sh
  569  ./script.sh
  570  cat ws5.txt
  571  input_file="Global YouTube Statistics.csv"; mkdir -p "Worksheet 5/United States"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do count=0; while IFS=',' read -r col1 col2 col3 col4 col5; do if [ "$col4" == "United States" ] && [ "$col5" == "$category" ]; then echo "$col1,$col2,$col3,$col4,$col5" >> "Worksheet 5/United States/$category.txt"; count=$((count+1)); fi; done < "$input_file"; echo "Number of entries in Worksheet 5/United States/$category.txt: $count" >> "ws5.txt"; done
  572  cat ws5.txt
  573  awk -F',' 'NR==1 {for (i=1; i<=NF; i++) if ($i == "Entertainment") print "Column " i " is Entertainment"}' "Global YouTube Statistics.csv"
  574  head -n 1 "Global YouTube Statistics.csv" | tr ',' '\n' | cat -n | grep "Entertainment"
  575  head -n 1 "Global YouTube Statistics.csv" | tr ',' '\n'| grep "Entertainment"
  576  head -n 1 'Global YouTube Statistics.csv' | tr ',' '\n' | grep -n 'highest_monthly_earnings'
  577  head -n 1 'Global YouTube Statistics.csv' | tr ',' '\n' | grep -n 'Entertainment
  578  head -n 1 'Global YouTube Statistics.csv' | tr ',' '\n' | grep -n 'Entertainment'
  579  input_file="Global YouTube Statistics.csv"; mkdir -p "Worksheet 5/United States"; categories=("Music" "Entertainment" "Gaming" "Comedy"); for category in "${categories[@]}"; do count=0; while IFS=',' read -r col1 col2 col3 col4 col5; do if [ "$col4" == "United States" ] && [ "$col5" == "$category" ]; then echo "$col1,$col2,$col3,$col4,$col5" >> "Worksheet 5/United States/$category.txt"; count=$((count+1)); fi; done < "$input_file"; echo "Number of entries in Worksheet 5/United States/$category.txt: $count" >> "ws5.txt"; done
  580  cat ws5.txt
  581  vi script.sh
  582  ./script.sh
  583  vi script.sh
  584  categories=("Music" "Entertainment" "Gaming" "Comedy"); while IFS=, read -r rank youtuber subscribers video_views category title uploads country abbreviation channel_type video_views_rank country_rank channel_type_rank video_views_for_the_last_30_days lowest_monthly_earnings highest_monthly_earnings lowest_yearly_earnings highest_yearly_earnings subscribers_for_last_30_days created_year created_month created_date gross_tertiary_education_enrollment population unemployment_rate urban_population latitude longitude; do if [[ "$country" == "United States" ]]; then echo "$rank,$youtuber,$subscribers,$video_views,$category,$title,$uploads,$country,$abbreviation,$channel_type,$video_views_rank,$country_rank,$channel_type_rank,$video_views_for_the_last_30_days,$lowest_monthly_earnings,$highest_monthly_earnings,$lowest_yearly_earnings,$highest_yearly_earnings,$subscribers_for_last_30_days,$created_year,$created_month,$created_date,$gross_tertiary_education_enrollment,$population,$unemployment_rate,$urban_population,$latitude,$longitude" >> "Worksheet 5/United States/${category}.txt"; fi; done < "Global YouTube Statistics.csv"; wc -w "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" "Worksheet 5/United States/Music.txt" >> ws5.txt
  585  cat ws5.txt
  586  cat "Worksheet 5/United States/Gaming.txt"
  587  history > cmds.log
  588  ls
  589  cd cs131
  590  cd Worksheet5
  591  ./script.sh
  592  vi script.sh
  593  cp script.sh oldscript.sh
  594  cat oldscript.sh
  595  vi script.sh
  596  cat script.sh
  597  chmod +x script.sh
  598  ./script.sh
  599  cat ws5.txt
  600  categories=("Music" "Entertainment" "Gaming" "Comedy"); while IFS=, read -r rank youtuber subscribers video_views category title uploads country abbreviation channel_type video_views_rank country_rank channel_type_rank video_views_for_the_last_30_days lowest_monthly_earnings highest_monthly_earnings lowest_yearly_earnings highest_yearly_earnings subscribers_for_last_30_days created_year created_month created_date gross_tertiary_education_enrollment population unemployment_rate urban_population latitude longitude; do if [[ "$country" == "United States" ]]; then echo "$rank,$youtuber,$subscribers,$video_views,$category,$title,$uploads,$country,$abbreviation,$channel_type,$video_views_rank,$country_rank,$channel_type_rank,$video_views_for_the_last_30_days,$lowest_monthly_earnings,$highest_monthly_earnings,$lowest_yearly_earnings,$highest_yearly_earnings,$subscribers_for_last_30_days,$created_year,$created_month,$created_date,$gross_tertiary_education_enrollment,$population,$unemployment_rate,$urban_population,$latitude,$longitude" >> "Worksheet 5/United States/${category}.txt"; fi; done < "Global YouTube Statistics.csv"; wc -w "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" "Worksheet 5/United States/Music.txt" >> ws5.txt
  601  cat script.sh
  602  ./script.sh
  603  vi script.sh
  604  ./script.sh
  605  cat ws5.txt
  606  cat "Worksheet 5/United States/Entertainment.txt"
  607  categories=("Music" "Entertainment" "Gaming" "Comedy"); while IFS=, read -r rank youtuber subscribers video_views category title uploads country abbreviation channel_type video_views_rank country_rank channel_type_rank video_views_for_the_last_30_days lowest_monthly_earnings highest_monthly_earnings lowest_yearly_earnings highest_yearly_earnings subscribers_for_last_30_days created_year created_month created_date gross_tertiary_education_enrollment population unemployment_rate urban_population latitude longitude; do if [[ "$country" == "United States" ]]; then echo "$rank,$youtuber,$subscribers,$video_views,$category,$title,$uploads,$country,$abbreviation,$channel_type,$video_views_rank,$country_rank,$channel_type_rank,$video_views_for_the_last_30_days,$lowest_monthly_earnings,$highest_monthly_earnings,$lowest_yearly_earnings,$highest_yearly_earnings,$subscribers_for_last_30_days,$created_year,$created_month,$created_date,$gross_tertiary_education_enrollment,$population,$unemployment_rate,$urban_population,$latitude,$longitude" >> "Worksheet 5/United States/${category}.txt"; fi; done < "Global YouTube Statistics.csv"; wc -w "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" "Worksheet 5/United States/Music.txt" >> ws5.txt
  608  cat ws5/txt
  609  cat ws5.txt
  610  vi script.sh
  611  ./script.sh
  612  vi ws5.txt
  613  cat ws5.txt
  614  cat script.txt
  615  cat script.sh
  616  ls
  617  rmdir 'Worksheet 5'
  618  rm -r 'Worksheet 5'
  619  ./script.sh
  620  mkdir -p "Workhsheet 5/United States"
  621  ./script
  622  ./script.sh
  623  ls
  624  categories=("Music" "Entertainment" "Gaming" "Comedy"); while IFS=, read -r rank youtuber subscribers video_views category title uploads country abbreviation channel_type video_views_rank country_rank channel_type_rank video_views_for_the_last_30_days lowest_monthly_earnings highest_monthly_earnings lowest_yearly_earnings highest_yearly_earnings subscribers_for_last_30_days created_year created_month created_date gross_tertiary_education_enrollment population unemployment_rate urban_population latitude longitude; do if [[ "$country" == "United States" ]]; then echo "$rank,$youtuber,$subscribers,$video_views,$category,$title,$uploads,$country,$abbreviation,$channel_type,$video_views_rank,$country_rank,$channel_type_rank,$video_views_for_the_last_30_days,$lowest_monthly_earnings,$highest_monthly_earnings,$lowest_yearly_earnings,$highest_yearly_earnings,$subscribers_for_last_30_days,$created_year,$created_month,$created_date,$gross_tertiary_education_enrollment,$population,$unemployment_rate,$urban_population,$latitude,$longitude" >> "Worksheet 5/United States/${category}.txt"; fi; done < "Global YouTube Statistics.csv"; wc -w "Worksheet 5/United States/Entertainment.txt" "Worksheet 5/United States/Gaming.txt" "Worksheet 5/United States/Comedy.txt" "Worksheet 5/United States/Music.txt" >> ws5.txt
  625  mkdir -p "Worksheet 5/United States"
  626  ls
  627  ls -l "Worksheet 5/United States"
  628  ./script.sh
  629  ws5.txt
  630  cat ws5.txt
  631  cd ..
  632  git add 
  633  git add .
  634  git add Worksheet5
  635  git status
  636  cd Worksheet5
  637  git init
  638  git commit -m"Worksheet5"
  639  git add
  640  git add .
  641  git init
  642  git push origin master
  643  git push -u origin master
  644  history > cmds.log
  645  git push origin master
  646  git push master
  647  git push master origin
  648  git status
  649  git add .
  650  cd ..
  651  git add Worksheet5
  652  cd Worksheet5
  653  git status
  654  git push --set-upstream origin master
  655  git branch
  656  git checkout -b master
  657  git checkout master
  658  git add .
  659  git commit -m "Initial commit"
  660  git push --set-upstream origin master
  661  git commit -m "Your commit message here"
  662  git push
  663  git push master origin
  664  git push origin master
  665  git push
  666  git checkout -b origin
  667  git push master origin
  668  git push --set-upstream origin master
  669  git commit -m "Message"
  670  git push --set-upstream origin master
  671  Please make sure you have the correct access rights
  672  and the repository exists.
  673  [hamzaf23@sjsu Worksheet5]$ 
  674  [hamzaf23@sjsu Worksheet5]$ git push --set-upstream origin master
  675  fatal: 'origin' does not appear to be a git repository
  676  fatal: Could not read from remote repository.
  677  Please make sure you have the correct access rights
  678  and the repository exists.Please make sure you have the correct access rights
  679  and the repository exists.
  680  [hamzaf23@sjsu Worksheet5]$ 
  681  [hamzaf23@sjsu Worksheet5]$ git push --set-upstream origin master
  682  fatal: 'origin' does not appear to be a git repository
  683  fatal: Could not read from remote repository.
  684  Please make sure you have the correct access rights
  685  and the repository exists.
  686  git remote add origin https://github.com/HKcode22/cs131
  687  git push --set-upstream origin master
  688  SHA256:qrEPJjVToUhzA65CLsJekd496eQWIZv9bUl2ZE912R4
  689  git push --set-upstream origin master
  690  git fetch origin
  691  git merge origin/master
  692  git merge --allow-unrelated-histories origin/master
  693  git push
  694  git push --set-upstream origin origin
  695  git add
  696  git add .
  697  git init
  698  git status
  699  cd ..
  700  git add Worksheet5
  701  cd ..
  702  cd cs131
  703  cd Worksheet5
  704  git push --set-upstream origin origin
  705  cd ..
  706  git push --set-upstream origin origi
  707  git push --set-upstream origin origin
  708  git push --set-upstream origin
  709  git push --set-upstream origin origi
  710  git push --set-upstream origin
  711  git push origin master
  712  cd Worksheet5
  713  git push origin master
  714  ws5.txt
  715  cat ws5.txt
  716  git push --force origin master
  717  cd ..
  718  git push --force origin master
  719  ls
  720  git add Worksheet5
  721  git add ,
  722  git add .
  723  git status
  724  git push --force origin master
  725  cd Wokrshett5
  726  cd Worksheet5
  727  git commit -m"add"
  728  git push origin master
  729  cd ..
  730  git push origin master
  731  git remote set-url origin git@github.com:HKcode22/cs131.git
  732  git push origin master
  733  git add .
  734  git add Worksheet5
  735  ls
  736  git push origin master
  737  cd Worksheet5
  738  git commit -m"add"
  739  git add .
  740  git commit -m"add"
  741  git push origin master
  742  git push --force origin master
  743  cd ..
  744  git push origin
  745  git push origin master
  746  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
  747  git push --force origin master
  748  ls
  749  git add Worksheet5
  750  mkdir Worksheet0
  751  git push --force origin master
  752  git add .
  753  git add Worksheet0
  754  git push --force origin master
  755  git push orign master
  756  git push --set-upstream origin master
  757  git commit -m "Message"
  758  git push --set-upstream origin master
  759  ls
  760  cd Worksheet5
  761  rm -r Wokrhseet1
  762  ls
  763  rm -r Worksheet1
  764  rm -r Worksheet2 | rm -r Worksheet4
  765  ls
  766  rm -r Assignment1 | rm -r Assignment2 | rm -r Worksheet3 | rm -r sampleProject
  767  ls
  768  git -m"add"
  769  git commit -m"add"
  770  cd ..
  771  git add .
  772  git add WOrksheet5
  773  git add Worksheet5
  774  git commit -m"message"
  775  git push --set-upstream origin master
  776  cd cs131
  777  mkdir Assignment3
  778  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/awkdata/last.fake
  779  cd Assignment3
  780  wget https://raw.githubusercontent.com/khanchandaniashish/CS131/main/awkdata/last.fake
  781  wget https://github.com/khanchandaniashish/CS131/blob/main/awkdata/passwd.fake 
  782  wget https://github.com/khanchandaniashish/CS131/blob/main/awkdata/ps.fake 
  783  ls
  784  wc -l last.fake
  785  grep 'f23' last.fake > lastf23.fake
  786  wc -l lastf23.fake
  787  grep 'Sun' lastf23.fake | awk '{print $1}' | sort -u
  788  awk '$NF >= 23 || $NF <= 4' lastf23.fake | awk '{print $1}' | sort -u
  789  awk '$NF >= 5 && $NF <= 9' lastf23.fake | awk '{print $1}' | sort -u
  790  awk '$1 ~ /^t/' lastf23.fake
  791  awk -F: '$1 ~ /^a/ && $3 % 2 == 0' passwd.fake
  792  sed -e 's/[a-zA-Z0-9 ]//g' passwd.fake | sort -u
  793  awk -F: -v OFS="\t" '$1 ~ /^a/ && $3 % 2 == 0' passwd.fake
  794  wc -l last.fake
  795  grep 'f23' last.fake > lastf23.fake
  796  wc -l lastf23.fake
  797  grep 'Sun' lastf23.fake | awk '{print $1}' | sort | uniq
  798  awk '$NF ~ /23$/ && $NF >= 11 && $NF <= 4 {print $1}' lastf23.fake | sort | uniq
  799  awk '$3 == "Sun" {print $1}' lastf23.fake | sort | uniq
  800  awk '$NF ~ /23$/ && $NF >= 11 && $NF <= 4 {print $1}' lastf23.fake | sort | uniq
  801  awk -F' ' '{split($6, a, ":"); if ((a[1] >= 23 && a[2] >= 0) || (a[1] <= 4 && a[2] >= 0)) print $1}' lastf23.fake | sort | uniq
  802  awk '$NF ~ /23$/ && $NF >= 5 && $NF <= 9 {print $1}' lastf23.fake | sort | uniq
  803  awk -F' ' '{split($6, a, ":"); if ((a[1] >= 5 && a[2] >= 0) && (a[1] <= 9 && a[2] >= 0)) print $1}' lastf23.fake | sort | uniq
  804  awk '$1 ~ /^t/ {print $1}' lastf23.fake
  805  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake
  806  awk -F: '$1 ~ /^a/ {print $1}' passwd.fake
  807  awk -F: '{print $1}' passwd.fake
  808  awk -F'{' '{print $1}' passwd.fake | grep -Eo 'a[^{]+' | awk '$1 % 2 == 0 {print}'
  809  cat passwd.fake
  810  awk -F'"' '$2 ~ /^a/ && $4 % 2 == 0 {print $2}' passwd.fake
  811  awk -F: '$1 ~ /^a/ && $3 % 2 == 0' passwd.fake
  812  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $0}' passwd.fake
  813  awk -F: '{ if ($1 ~ /^a/ && $3 % 2 == 0) print $0 }' passwd.fake
  814  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake
  815  sed -E 's/[a-zA-Z0-9 ]//g' passwd.fake | sort -u
  816  cat passwd.fake
  817  grep "a" paawk -F: '$1 ~ /^a/' passwd.fake
  818  awk -F: '$1 ~ /^a/' passwd.fake
  819  grep '^a' passwd.fake
  820  man last
  821  awk '$4 ~ /Sun/ {print $1}' lastf23.fake | sort | uniq
  822  awk '$4 ~ /Sun/ {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} \
  823       {print $0} \
  824       END {print "Kudos to these people for putting in the work"}'
  825  awk '$4 ~ /Sun/ {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  826  awk '$5 ~ /11:/, $5 ~ /04:/{print $1}' lastf23.fake | sort | uniq
  827  awk '($5 >= "23:00" || $5 <= "04:00"){print $1}' lastf23.fake | sort | uniq
  828  awk '($5 >= "23:00" || $5 <= "04:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  829  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  830  h
  831  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  832  awk '($5 >= "05:00" && $5 <= "09:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Early Birds List:"} {print $0} END {print "Early Birds are dope. Please ensure you get enough sleep though."}'
  833  awk '$5 >= "05:00" && $5 <= "09:00" {print $1}' lastf23.fake | sort | uniq
  834  awk '$NF ~ /([5-9]:[0-5][0-9]:[0-5][0-9])|(09:00:00)/ {print $1}' last.fake | sort | uniq
  835  cat last.fake
  836  awk '$NF >= "05:00:00" && $NF <= "09:00:00" {print $1}' last.fake | sort | uniq
  837  awk '{split($10, a, ":"); if (a[1] >= 5 && a[1] <= 9) print $1}' last.fake | sort | uniq
  838  awk '$NF ~ /:[0-9][0-9]:[0-9][0-9]/ && $NF >= ":05:00" && $NF <= ":09:00" {print $1}' last.fake | sort | uniq
  839  grep -Eo '^[^[:space:]]+' last.fake | awk -F: '$1 >= 5 && $1 <= 9 {print $1}' | sort | uniq
  840  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  841  awk '($5 >= "05:00" || ($5 <= "09:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  842  awk '($5 >= "05:00" && ($5 <= "09:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  843  awk '($5 >= "05:00" && $5 <= "09:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Early Birds List:"} {print $0} END {print "Early Birds are dope. Please ensure you get enough sleep though."}'
  844  awk '$7 >= 5 && $7 <= 9 {print $1}' lastf23.fake | sort -u
  845  awk '{print $1}' lastf23.fake | sort -u
  846  cat lastf23.fake
  847  cat last.fake
  848  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  849  print $0
  850  awk '{print $1}' lastf23.fake | sort -u
  851  awk '{print $0}' lastf23.fake | sort -u
  852  awk '{print $2}' lastf23.fake | sort -u
  853  awk '{print $3}' lastf23.fake | sort -u
  854  awk '{print $4}' lastf23.fake | sort -u
  855  awk '{print $5}' lastf23.fake | sort -u
  856  awk '{print $6}' lastf23.fake | sort -u
  857  awk '{print $7}' lastf23.fake | sort -u
  858  awk '{print $8}' lastf23.fake | sort -u
  859  awk '{print $5}' lastf23.fake | sort -u
  860  awk '($6 >= "23:00" || ($6 >= "00:00" && $6 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  861  awk '($7 >= "23:00" || ($7 >= "00:00" && $7 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  862  awk '($7 >= "23:00" || ($7 >= "00:00" && $7 <= "04:00")){print $1}' lastf23.fake | sort | uniq
  863  awk '{print $1}' lastf23.fake | sort -u
  864  awk '$4 >= "10:00:00" && $4 <= "12:00:00" { print $1 }' logfile.txt
  865  awk '$2 >= "10:00" && $2 <= "12:00" { print $1 }' lastf23.fake | sort | uniq
  866  awk '$2 >= "10:00" && $2 <= "12:00" { print $1 }' lastf23.fake
  867  awk '$2 >= ("10:00" && $2 <= "12:00") { print $1 }' lastf23.fake
  868  awk '{print $0}' your_data_file
  869  cat lastf23.fake
  870  awk '($7 >= "23:00" && $8 <= "04:00") {print $1}' lastf23.fake | sort -u
  871  awk '($7 >= "05:00" && $8 <= "09:00") {print $1}' lastf23.fake | sort -u
  872  awk {print $7}
  873  awk '{print &7}'
  874  awk '{print $7}
  875  awk '{print &7}'
  876  awk '{print $7}'
  877  awk '{print $7}' lastf23.fake
  878  awk '{print $8}' lastf23.fake
  879  awk '{print $9}' lastf23.fake
  880  awk '($7 >= "23:00" && $9 <= "04:00") {print $1}' lastf23.fake | sort -u
  881  awk '($7 >= "23:00" && $8 <= "04:00") {print $1}' lastf23.fake | sort -u
  882  awk '($7 >= "05:00" && $9 <= "09:00") {print $1}' lastf23.fake | sort -u
  883  awk '($7 >= "05:00" && $8 <= "09:00") {print $1}' lastf23.fake | sort -u
  884  cd cs131
  885  cd Assignment3
  886  vi Assignment3.txt
  887  cd cs131
  888  cd Assignment3
  889  cd cs131
  890  cd Assignment3
  891  vi Assignment3.txt
  892  vi Assingment3.txt
  893  cat Assingmnt3.txt
  894  cat Assignment3.txt
  895  cat Assingmnt3.txt
  896  ls
  897  cat Assingment3.txt
  898  cp Assingment3.txt Assignment3.txt
  899  ls
  900  cat Assignment3.txt
  901  cd cs131
  902  cd ..
  903  git add .
  904  git add Assignment3
  905  git status
  906  cd Assignment3
  907  history > cmds.log
  908  ls
  909  cd ..
  910  git add .
  911  git add Assignment3
  912  git status
  913  cd Assignment3
  914  git commit -m"add"
  915  git push orgin master
  916  git push --set-upstream origin master
  917  cd cs131
  918  cd Assignment3
  919  awk '{print $1}' lastf23.fake | sort -u
  920  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  921  awk '($5 >= "23:00" || ($5 >= "00:00" && $5 <= "04:00")){print $1}' lastf23.fake | sort | uniq | awk 'BEGIwc -l last.fakeN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  922  wc -l last.fake
  923  grep 'f23' last.fake > lastf23.fake
  924  wc -l lastf23.fake
  925  cat lastf23.fake
  926  awk '$4=="Sun" {print $1}' lastf23.fake | sort | uniq
  927  awk '$4==Sun {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  928  '$4==Sun {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  929  The list of people who worked on'$4==Sun {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  930  The list of people who worked on
  931  awk '($4==Sun) {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  932  awk '($4=="Sun") {print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "The list of people who worked on Sunday are:"} {print $0} END {print "Kudos to these people for putting in the work"}'
  933  awk '($7 >= "23:00" && $8 <= "04:00") {print $1}' lastf23.fake | sort -uawk '($7 >= "23:00" && $8 <= "04:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  934  awk '($7 >= "23:00" && $8 <= "04:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print $0} END {print "Night Owls are dope. Please ensure you get enough sleep though."}'
  935  awk '($7 >= "05:00" && $8 <= "09:00"){print $1}' lastf23.fake | sort | uniq | awk 'BEGIN {print "Early Birds List:"} {print $0} END {print "Early Birds are dope. Please ensure you get enough sleep though."}'
  936  awk '$1 ~ /^t/' lastf23.fake | sort -u
  937  awk '$1 ~ /^a/ && $3 % 2 == 0' passwd.fake | sort -u
  938  awk '($1 ~ /^a/ && $3 % 2 == 0)' passwd.fake | sort -u
  939  xawk '($1 ~ /^a/ && $3 % 2 == 0)' passwd.fake | sort -u
  940  awk '($1==/^a/ && $3 % 2 == 0)' passwd.fake | sort -u
  941  awk '($1 ~ /^a/ && $3 % 2 == 0)' passwd.fake | sort -uawk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake | sort -u
  942  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake | sort -u
  943  awk -F: '($1 ~ /^a/) && ($3 % 2 == 0) {print $1}' passwd.fake | sort -u
  944  awk -F: '($1 ~ /^a/) && ($2 % 2 == 0) {print $1}' passwd.fake | sort -u
  945  sed 's/[a-zA-Z0-9 ]//g' passwd.fake | sort -u
  946  cd cs131
  947  ls
  948  mkdir MiniProjectGroup2
  949  cd MiniProjectGroup2
  950  https://www.kaggle.com/datasets/alexq1111/imdb-top-rated-english-movies/
  951  pip install kaggle
  952  wget how do i donwload https://www.kaggle.com/datasets/alexq1111/imdb-top-rated-english-movies/ to mac book terminal
  953  wget https://www.kaggle.com/datasets/alexq1111/imdb-top-rated-english-movies/
  954  ls
  955  cat index.html
  956  ls
  957  index.html.1
  958  cat index.html.1
  959  touch Names.txt
  960  echo -e "Abdul\nHamza\nRogelio" > Names.txt
  961  history > cmds.log
  962  cd ..
  963  git add .
  964  git add MiniPojectGroup2
  965  git add MiniProjectGroup2
  966  git status
  967  cd MiniProjectGroup2
  968  git commit -m"added"
  969  git push origin master
  970  cd cs131
  971  ls
  972  cd MiniProjectGroup2
  973  ls
  974  rm *.html
  975  ls
  976  rm index.html.1
  977  ls
  978  wget -O topmovies.csv
  979  wget topmovies.csv https://www.kaggle.com/datasets/omarhanyy/imdb-top-1000
  980  ls
  981  cat imdb-top-1000
  982  ls
  983  rm imdb-top-1000
  984  cat topmovies.csv
  985  cd ~/Downloads
  986  cat /path/to/your/local/Downloads/file.csv
  987  wget https://www.kaggle.com/omarhanyy/imdb-top-1000/raw/master/topmovies.csv
  988  ls
  989  wget https://www.kaggle.com/omarhanyy/imdb-top-1000/raw/master/topmovies.csv
  990  curl -O https://www.kaggle.com/omarhanyy/imdb-top-1000/raw/master/topmovies.csv
  991  ls
  992  cat topmovies.csv
  993  curl -O https://www.kaggle.com/omarhanyy/imdb-top-1000/raw/master/topmovies.csv
  994  ls
  995  curl -I https://www.kaggle.com/omarhanyy/imdb-top-1000/raw/master/topmovies.csv
  996  cat topmovies.csv
  997  pip install kaggle
  998  sudo apt-get update
  999  pip install kaggle
 1000  wget -O "IMDB_top_1000.csv" "https://www.kaggle.com/omarhanyy/imdb-top-1000/download"
 1001  ls
 1002  cat IMDB_top_1000.csv
 1003  wget --cookies=on --header "Cookie: _kaggle_session=$(curl -s -b cookies.txt https://www.kaggle.com/account/login?returnUrl=%2Fdatasets%2Fomarhanyy%2Fimdb-top-1000 | grep -o 'csrf_token" content="[a-z0-9]\+"' | grep -o '[a-z0-9]\+' | head -n 1)" -O "IMDB_top_1000.csv" "https://www.kaggle.com/omarhanyy/imdb-top-1000/download"
 1004  .s
 1005  ls
 1006  cat IMDB_top_1000.csv
 1007  curl -LJO https://www.kaggle.com/datasets/omarhanyy/imdb-top-1000/download/IMDB%20top%201000.csv
 1008  wget --content-disposition https://www.kaggle.com/datasets/omarhanyy/imdb-top-1000/download/IMDB%20top%201000.csv
 1009  ls
 1010  cat IMDB%20top%201000.csv
 1011  ls
 1012  cat IMDB_top_1000.csv
 1013  ls
 1014  pip install kaggle
 1015  kaggle login
 1016  pip3 install kaggle
 1017  kaggle login
 1018  pip install kaggle
 1019  pip3 install --upgrade pip
 1020  pip3 install --force-reinstall kaggle
 1021  pip install kaggle
 1022  kaggle login
 1023  brew install python3
 1024  pip3 install kaggle
 1025  python3 -m kaggle
 1026  python -m kaggle
 1027  kaggle login
 1028  export PATH="/mnt/scratch/FA23_CS131_Ashish/hamzaf23/.local/bin:$PATH"
 1029  source ~/.bashrc   # or source ~/.zshrc if you're using Zsh
 1030  kaggle login
 1031  export KAGGLE_USERNAME=hamzakhansjsu
 1032  export KAGGLE_KEY=8a24a58f5bd43a51354fb2a7a66184d0
 1033  kaggle login
 1034  kaggle competitions list
 1035  export KAGGLE_USERNAME=hamzakhansjsu
 1036  export KAGGLE_KEY=8a24a58f5bd43a51354fb2a7a66184d0
 1037  pip3 install --upgrade kaggle
 1038  kaggle competitions list
 1039  pip install kaggle
 1040  chmod 600 ~/.kaggle/kaggle.json
 1041  kaggle datasets download -d omarhanyy/imdb-top-1000
 1042  unzip imdb-top-1000.zip
 1043  ls
 1044  cat 'IMDB top 1000.csv'
 1045  ls
 1046  cat IMDB%20top%201000.csv
 1047  ls
 1048  rm IMDB%20top%201000.csv
 1049  ls
 1050  cat 'IMDB top 1000.csv'
 1051  ls
 1052  cat  IMDB_top_1000.csv
 1053  ls
 1054  rm  IMDB_top_1000.csv
 1055  ls
 1056  cat imdb-top-1000.zip
 1057  1;2c
 1058  ls
 1059  rm imdb-top-1000.zip
 1060  ls
 1061  cat 'login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fdatasets%2Fomarhanyy%2Fimdb-top-1000?resource=download'
 1062  ls
 1063  rm 'login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fdatasets%2Fomarhanyy%2Fimdb-top-1000?resource=download'
 1064  ls
 1065  cat topmovies.csv
 1066  rm topmovies.csv
 1067  ls
 1068  cat 'IMDB top 1000.csv'
 1069  history > cmds.log
